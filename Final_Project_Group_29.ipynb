{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SW9W1U_c9_9J"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import music21\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "oLXnjXn226KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "UAFezSsc26Gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "1G9SBG1D5iVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wtc6XUCmAYkU"
      },
      "outputs": [],
      "source": [
        "# 1. Data Preprocessing\n",
        "def extract_notes_and_durations(file_path):\n",
        "    midi = music21.converter.parse(file_path)\n",
        "    notes = []\n",
        "    durations = []\n",
        "\n",
        "    for element in midi.flatten():\n",
        "        if isinstance(element, music21.note.Note):\n",
        "            notes.append(element.pitch.midi)\n",
        "            durations.append(element.duration.quarterLength)\n",
        "        elif isinstance(element, music21.chord.Chord):\n",
        "            notes.append(element.sortAscending().pitches[-1].midi)\n",
        "            durations.append(element.duration.quarterLength)\n",
        "\n",
        "    return notes, durations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "owe3zoPD9-H5"
      },
      "outputs": [],
      "source": [
        "def process_midi_files(directory):\n",
        "    all_notes = []\n",
        "    all_durations = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            if file.endswith('.mid') or file.endswith('.midi'):\n",
        "                try:\n",
        "                    path = os.path.join(root, file)\n",
        "                    notes, durations = extract_notes_and_durations(path)\n",
        "                    all_notes.extend(notes)\n",
        "                    all_durations.extend(durations)\n",
        "                except Exception as e:\n",
        "                    print(f\"Error processing {file}: {str(e)}\")\n",
        "\n",
        "    return all_notes, all_durations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ls8l5e-i9zJJ"
      },
      "outputs": [],
      "source": [
        "def create_sequences(notes, durations, sequence_length):\n",
        "    X = []\n",
        "    y_notes = []\n",
        "    y_durations = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        X.append(list(zip(notes[i:i + sequence_length], durations[i:i + sequence_length])))\n",
        "        y_notes.append(notes[i + sequence_length])\n",
        "        y_durations.append(durations[i + sequence_length])\n",
        "    return np.array(X), np.array(y_notes), np.array(y_durations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Za-KGfWv_pEy"
      },
      "outputs": [],
      "source": [
        "# 2. Model Definition\n",
        "def create_model(input_shape, vocab_size):\n",
        "    model = Sequential([\n",
        "        LSTM(256, input_shape=input_shape, return_sequences=True),\n",
        "        Dropout(0.3),\n",
        "        LSTM(256),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(vocab_size, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNfB_BjkkQWj"
      },
      "outputs": [],
      "source": [
        "def save_model_and_data(model, notes, vocab_size, sequence_length, output_dir):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Save the model\n",
        "    model.save(os.path.join(output_dir, 'music_model.h5'))\n",
        "\n",
        "    # Save the notes and other necessary data\n",
        "    data = {\n",
        "        'notes': notes,\n",
        "        'vocab_size': vocab_size,\n",
        "        'sequence_length': sequence_length\n",
        "    }\n",
        "    with open(os.path.join(output_dir, 'music_data.pkl'), 'wb') as f:\n",
        "        pickle.dump(data, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KBHpCOJF_xg4"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKa9b6TP_VUU"
      },
      "outputs": [],
      "source": [
        "def tune_hyperparameters(X, y):\n",
        "    best_lr = 0.001\n",
        "    best_batch_size = 64\n",
        "    best_epochs = 5\n",
        "    best_val_acc = 0.0\n",
        "\n",
        "    # Simplified grid search\n",
        "    for lr in [0.001, 0.01, 0.1]:\n",
        "        for batch_size in [32, 64, 128]:\n",
        "            model = create_model(X.shape[1:], vocab_size)\n",
        "            optimizer = Adam(learning_rate=lr)\n",
        "            model.add(Dense(128, activation='softmax'))\n",
        "            model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "            y_train_onehot = to_categorical(y_train)\n",
        "            history = model.fit(X, y_train_onehot, validation_split=0.2, epochs=5, batch_size=batch_size, verbose=0)\n",
        "\n",
        "            val_acc = max(history.history['val_accuracy'])\n",
        "            if val_acc > best_val_acc:\n",
        "                best_val_acc = val_acc\n",
        "                best_lr = lr\n",
        "                best_batch_size = batch_size\n",
        "                best_epochs = len(history.history['val_accuracy'])\n",
        "\n",
        "    return best_lr, best_batch_size, best_epochs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_directory = '/content/drive/MyDrive/clean_midi'\n",
        "output_directory = '/content/drive/MyDrive'\n",
        "sequence_length = 100"
      ],
      "metadata": {
        "id": "fEaYhrK_wa5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process MIDI files\n",
        "print(\"Processing MIDI files...\")\n",
        "all_notes, all_durations = process_midi_files(data_directory)"
      ],
      "metadata": {
        "id": "RDVAC0WvwbWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences\n",
        "print(\"Creating sequences...\")\n",
        "X, y_notes, y_durations = create_sequences(all_notes, all_durations, sequence_length)"
      ],
      "metadata": {
        "id": "MKnbKypKwiKt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare data for model\n",
        "vocab_size = max(all_notes) + 1\n",
        "X = np.array([[[n/vocab_size, d] for n, d in seq] for seq in X]).astype(np.float32)"
      ],
      "metadata": {
        "id": "anUS_yvgwm70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_notes, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tune hyperparameters\n",
        "print(\"Tuning hyperparameters...\")\n",
        "best_lr, best_batch_size, best_epochs = tune_hyperparameters(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "hSD2SNwfwrdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create and train model\n",
        "print(\"Creating and training model...\")\n",
        "model = create_model((X.shape[1], X.shape[2]), vocab_size)\n",
        "optimizer = Adam(learning_rate=best_lr)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer, metrics=[accuracy])\n"
      ],
      "metadata": {
        "id": "6g2WuhMawtko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "model_checkpoint = ModelCheckpoint(os.path.join(output_directory, 'best_model.keras'), save_best_only=True)\n",
        "\n",
        "# Train model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=best_batch_size,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ") #supposed to use best_epochs but cannot run without crashing"
      ],
      "metadata": {
        "id": "eaQhZt5pwxFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model\n",
        "history_test = model.fit(\n",
        "    X_test, y_test,\n",
        "    validation_split=0.2,\n",
        "    epochs=5,\n",
        "    batch_size=best_batch_size,\n",
        "    callbacks=[early_stopping, model_checkpoint]\n",
        ") #supposed to use best_epochs but cannot run without crashing"
      ],
      "metadata": {
        "id": "0mI-wrOSVYYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5l4lyOATDxEh"
      },
      "outputs": [],
      "source": [
        "# Save model and data\n",
        "model.save(os.path.join(output_directory, 'm_model.keras'))\n",
        "with open(os.path.join(output_directory, 'training_hist.pkl'), 'wb') as f:\n",
        "    pickle.dump(history.history, f)\n",
        "\n",
        "print(f\"Model and data saved in {output_directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofX6Oxj1HaTL"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}